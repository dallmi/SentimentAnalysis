# Verwendungs-Anleitung - Artikel-Analyse mit LLM

## ðŸŽ¯ Dein Use Case

Du mÃ¶chtest:
1. âœ… URLs von News & Events Artikeln analysieren
2. âœ… Artikel-Inhalte verstehen und kategorisieren
3. âœ… Kommentare analysieren (Sentiment)
4. âœ… Korrelation finden: Welche Artikel-Typen â†’ positives/negatives Feedback
5. âœ… Artikel clustern (Ã¤hnliche Artikel gruppieren)

## ðŸ“Š Input-Format

### Excel-Datei vorbereiten:

```
Spalte A (URL)                              | Spalte B (Kommentar)
-------------------------------------------|---------------------------
https://intranet.firma.de/artikel/123      | Great article, very helpful!
https://intranet.firma.de/artikel/123      | Thanks for sharing
https://intranet.firma.de/artikel/456      | Not clear, confusing
https://intranet.firma.de/artikel/456      | Could be better explained
https://intranet.firma.de/artikel/789      | Excellent overview!
```

**Wichtig:**
- Mehrere Zeilen pro Artikel mÃ¶glich (fÃ¼r mehrere Kommentare)
- URLs werden automatisch gruppiert
- Kommentare werden pro Artikel aggregiert

### Speicherort:

```
data/input/deine_artikel.xlsx
```

---

## ðŸš€ Verwendung

### Option 1: Standard (mit LLM Model)

```bash
python main_with_llm.py --input data/input/deine_artikel.xlsx
```

**Was passiert:**
1. LÃ¤dt Excel-Datei
2. Scrapt Artikel-Inhalte von URLs
3. Analysiert Kommentare mit **BERT-Model** (hohe Genauigkeit)
4. Kategorisiert Artikel nach **Content-Themen** (KI & Innovation, Mitarbeiter-Stories, Events, etc.)
5. Clustert Ã¤hnliche Artikel
6. Erstellt detaillierten Excel-Report

**Dauer:** ~3-5 Minuten fÃ¼r 50 Artikel (Model-Loading + Analyse)

### Option 2: Schneller (ohne LLM)

```bash
python main_with_llm.py --input data/input/deine_artikel.xlsx --no-llm
```

**Verwendet Lexikon-Modus:**
- âœ… ~10x schneller
- âš ï¸ Etwas geringere Genauigkeit

### Option 3: Ohne Web Scraping

Falls URLs nicht erreichbar oder nur Kommentare wichtig:

```bash
python main_with_llm.py --input data/input/deine_artikel.xlsx --no-scraping
```

### Option 4: Ohne Clustering

```bash
python main_with_llm.py --input data/input/deine_artikel.xlsx --no-clustering
```

---

## ðŸ“ˆ Output

### Generierte Datei:

```
data/output/llm_analysis_20251022_143022.xlsx
```

### Sheets:

#### 1. **Artikel** - Ãœbersicht aller Artikel
| URL | Titel | Content-Thema | Cluster | Avg_Sentiment | Total_Comments | Positive | Negative | Neutral |
|-----|-------|---------------|---------|---------------|----------------|----------|----------|---------|
| ... | ...   | Mitarbeiter-Stories | Mitarbeiter-Stories_interview | +0.85 | 12 | 10 | 1 | 1 |

#### 2. **Kategorien** - Sentiment pro Content-Thema â­ **WICHTIGSTE ANSICHT**
| Content-Thema | Avg_Sentiment | Anzahl_Artikel | Positive_Kommentare | Negative_Kommentare |
|---------------|---------------|----------------|---------------------|---------------------|
| Mitarbeiter-Stories | +0.88 | 15 | 142 | 5 |
| Events & Networking | +0.75 | 20 | 158 | 18 |
| Wellness & Benefits | +0.68 | 12 | 95 | 12 |
| KI & Innovation | +0.45 | 25 | 145 | 48 |
| Organisatorische Ã„nderungen | -0.15 | 12 | 35 | 75 |

**â†’ Interpretation:** Mitarbeiter-Stories bekommen bestes Feedback! ðŸŽ¯

#### 3. **Clusters** - Thematische Gruppen innerhalb der Content-Themen
| Cluster | Avg_Sentiment | Anzahl_Artikel |
|---------|---------------|----------------|
| HR_recruiting | +0.88 | 8 |
| IT_software_update | +0.35 | 12 |
| Management_restructuring | -0.22 | 5 |

**â†’ Interpretation:** Recruiting-Artikel sehr positiv, Restructuring negativ

#### 4. **Insights** - Top & Worst Artikel
- Top 5 Artikel mit bestem Feedback
- Worst 5 Artikel mit schlechtestem Feedback

---

## ðŸ” Wie funktioniert die Kategorisierung?

Das System verwendet **Keyword-Matching**:

```python
CATEGORY_KEYWORDS = {
    'HR': ['mitarbeiter', 'personal', 'recruiting', 'bewerbung', 'employee', 'hiring'],
    'IT': ['software', 'hardware', 'system', 'update', 'server', 'application'],
    'Management': ['strategie', 'fÃ¼hrung', 'management', 'leadership', 'restructuring'],
    'Training': ['schulung', 'training', 'workshop', 'seminar', 'course'],
    'Benefits': ['benefits', 'urlaub', 'gehalt', 'salary', 'bonus', 'pension'],
    # ... weitere Kategorien
}
```

**Du kannst eigene Kategorien hinzufÃ¼gen** in `config/settings.py`!

---

## ðŸŽ¨ Clustering-Logik

Artikel werden geclustert basierend auf:
1. **Hauptkategorie** (HR, IT, etc.)
2. **Dominantes Keyword** (das hÃ¤ufigste Keyword)

**Beispiel:**
- Artikel Ã¼ber "Recruiting" â†’ Cluster: `HR_recruiting`
- Artikel Ã¼ber "Benefits" â†’ Cluster: `HR_benefits`
- Artikel Ã¼ber "Software-Update" â†’ Cluster: `IT_software`

â†’ So siehst du **welche Themen innerhalb einer Kategorie** gut/schlecht ankommen!

---

## ðŸ’¡ Erweiterte Verwendung

### Custom Spalten

```bash
python main_with_llm.py \
  --input data/input/datei.xlsx \
  --url-column C \
  --comment-column D
```

### Alle Optionen

```bash
python main_with_llm.py --help
```

Zeigt:
```
--input PATH          Input Excel-Datei
--url-column COL      Spalte mit URLs (Standard: A)
--comment-column COL  Spalte mit Kommentaren (Standard: B)
--no-llm             Verwende Lexikon statt LLM
--no-scraping        Ãœberspringe Web Scraping
--no-clustering      Ãœberspringe Clustering
```

---

## ðŸ“Š Beispiel-Workflow

### Schritt 1: Daten vorbereiten

```bash
# Lege Excel-Datei ab
cp meine_artikel.xlsx data/input/
```

### Schritt 2: Analyse ausfÃ¼hren

```bash
# In Corporate-Umgebung (Windows)
cd P:\IMPORTANT\Projects\SentimentAnalysis
python main_with_llm.py --input data/input/meine_artikel.xlsx
```

**Output:**
```
==============================================================================
  ERWEITERTE SENTIMENT-ANALYSE mit LLM & CLUSTERING
==============================================================================
Input-Datei: data/input/meine_artikel.xlsx

[1/6] Lade Daten aus Excel...
âœ“ 150 Zeilen geladen
âœ“ 50 unique Artikel gefunden

[2/6] Scrape Artikel-Inhalte...
  Scraping 1/50: https://intranet.firma.de/artikel/123
  ...
âœ“ 50 Artikel gescraped

[3/6] Sentiment-Analyse der Kommentare...
Lade LLM Model (kann ~60s dauern)...
âœ“ LLM Model geladen (Mode: bert)
Analysiere 150 Kommentare mit bert Model...
âœ“ 150 Kommentare analysiert
  Durchschnittliches Sentiment: +0.456

[4/6] Kategorisiere Artikel...
âœ“ Kategorisierung abgeschlossen
  - HR: 15 Artikel
  - IT: 20 Artikel
  - Management: 10 Artikel
  - Training: 5 Artikel

[5/6] Clustere Artikel...
âœ“ 12 Cluster gefunden
  - HR_recruiting: 8 Artikel
  - IT_software: 12 Artikel
  - Management_strategy: 6 Artikel

Top Cluster nach Sentiment:
  HR_recruiting: 8 Artikel, Sentiment: +0.88
  Training_workshop: 5 Artikel, Sentiment: +0.76
  IT_software: 12 Artikel, Sentiment: +0.42
  ...

[6/6] Erstelle Reports...
âœ“ Report gespeichert: data/output/llm_analysis_20251022_143022.xlsx

==============================================================================
  ZUSAMMENFASSUNG
==============================================================================
Analysierte Artikel: 50
Total Kommentare: 150
Durchschn. Sentiment: +0.456
LLM Model: bert

âœ… Analyse abgeschlossen! Report: data/output/llm_analysis_20251022_143022.xlsx
```

### Schritt 3: Report Ã¶ffnen

```bash
# Windows
start data\output\llm_analysis_20251022_143022.xlsx

# macOS
open data/output/llm_analysis_20251022_143022.xlsx
```

### Schritt 4: Insights interpretieren

**Frage:** Welche Artikel-Typen bekommen positives Feedback?

**Antwort aus Report:**
1. Ã–ffne Sheet "Kategorien"
2. Sortiere nach "Avg_Sentiment" (absteigend)
3. â†’ Top-Kategorien sehen!

**Beispiel-Ergebnis:**
```
1. Training: +0.82 â†’ Mitarbeiter lieben Trainings-AnkÃ¼ndigungen!
2. HR: +0.65      â†’ HR-News kommen gut an
3. IT: +0.42      â†’ IT-Updates ok
4. Management: +0.15 â†’ Management-News weniger beliebt
```

**Actionable Insights:**
- âœ… Mehr Training-Artikel verÃ¶ffentlichen
- âœ… HR-Content funktioniert gut
- âš ï¸ IT-Updates verstÃ¤ndlicher schreiben
- âš ï¸ Management-Kommunikation verbessern

---

## ðŸ”§ Performance-Tipps

### FÃ¼r viele Artikel (>100):

```bash
# Verwende Lexikon-Modus (schneller)
python main_with_llm.py --input datei.xlsx --no-llm

# Oder: Erst ohne Scraping testen
python main_with_llm.py --input datei.xlsx --no-scraping
```

### FÃ¼r wenige Artikel (<50):

```bash
# Verwende LLM fÃ¼r beste Genauigkeit
python main_with_llm.py --input datei.xlsx
```

---

## ðŸ“ Eigene Kategorien hinzufÃ¼gen

Bearbeite `config/settings.py`:

```python
CATEGORY_KEYWORDS = {
    'HR': ['mitarbeiter', 'personal', ...],
    'IT': ['software', 'hardware', ...],

    # FÃ¼ge eigene Kategorie hinzu:
    'Sustainability': ['nachhaltigkeit', 'umwelt', 'green', 'co2', 'klimaschutz'],
    'Innovation': ['innovation', 'digital', 'transformation', 'ai', 'ki'],
}
```

Dann funktioniert die Kategorisierung automatisch mit deinen neuen Kategorien!

---

## ðŸ†˜ Troubleshooting

### "LLM Solution nicht verfÃ¼gbar"
â†’ Stelle sicher, dass `LLM Solution/` Ordner existiert und `transformers` installiert ist

### "Keine Input-Datei gefunden"
â†’ Lege Excel-Datei in `data/input/` ab oder verwende `--input pfad`

### "Model Loading dauert zu lange"
â†’ Verwende `--no-llm` fÃ¼r Lexikon-Modus (schneller)

### "Scraping schlÃ¤gt fehl"
â†’ Verwende `--no-scraping` falls URLs nicht erreichbar

---

## ðŸŽ¯ NÃ¤chste Schritte

1. **Teste mit kleinem Datensatz** (10-20 Artikel)
2. **PrÃ¼fe Kategorisierung** - passe Keywords an wenn nÃ¶tig
3. **Interpretiere Cluster** - welche Themen funktionieren?
4. **Skaliere** auf vollstÃ¤ndigen Datensatz

**Viel Erfolg!** ðŸš€
