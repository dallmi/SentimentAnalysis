# Quickstart: Artikel-Analyse mit LLM

## ğŸ¯ Dein Ziel

URLs von News & Events Artikeln analysieren und verstehen:
- **Welche Artikel-Typen bekommen positives Feedback?**
- **Welche Artikel-Typen bekommen negatives Feedback?**

## ğŸ“Š 1. Excel-Datei vorbereiten

Erstelle eine Excel-Datei mit 2 Spalten:

```
Spalte A (URL)                              | Spalte B (Kommentar)
-------------------------------------------|---------------------------
https://intranet.firma.de/artikel/123      | Great article!
https://intranet.firma.de/artikel/123      | Very helpful
https://intranet.firma.de/artikel/456      | Not clear
https://intranet.firma.de/artikel/789      | Excellent!
```

**Speichere die Datei in:**
```
data/input/meine_artikel.xlsx
```

## ğŸš€ 2. Analyse starten

### In Corporate-Umgebung (Windows):

```cmd
cd P:\IMPORTANT\Projects\SentimentAnalysis
python main_with_llm.py --input data/input/meine_artikel.xlsx
```

### Optionen:

```bash
# Standard (mit LLM Model - hohe Genauigkeit)
python main_with_llm.py --input data/input/meine_artikel.xlsx

# Schneller Modus (Lexikon statt LLM - geringere Genauigkeit)
python main_with_llm.py --input data/input/meine_artikel.xlsx --no-llm

# Ohne Web Scraping (nur Kommentar-Analyse)
python main_with_llm.py --input data/input/meine_artikel.xlsx --no-scraping

# Ohne Clustering
python main_with_llm.py --input data/input/meine_artikel.xlsx --no-clustering
```

## ğŸ“ˆ 3. Ergebnis Ã¶ffnen

Die Analyse erstellt eine Excel-Datei:
```
data/output/llm_analysis_20251022_143022.xlsx
```

**Diese Datei Ã¶ffnen:**
```cmd
start data\output\llm_analysis_20251022_143022.xlsx
```

## ğŸ“Š 4. Ergebnisse interpretieren

### Sheet "Kategorien" - **Wichtigste Ansicht!**

Hier siehst du die Antwort auf deine Frage:

| Kategorie | Avg_Sentiment | Anzahl_Artikel | Positive_Kommentare | Negative_Kommentare |
|-----------|---------------|----------------|---------------------|---------------------|
| Training  | +0.82         | 15             | 120                 | 8                   |
| HR        | +0.65         | 25             | 180                 | 45                  |
| IT        | +0.42         | 30             | 145                 | 78                  |
| Management| +0.15         | 10             | 65                  | 52                  |

**Interpretation:**
- âœ… **Training-Artikel** bekommen bestes Feedback (+0.82)
- âœ… **HR-Artikel** kommen gut an (+0.65)
- âš ï¸ **IT-Artikel** sind ok (+0.42)
- âš ï¸ **Management-Artikel** brauchen Verbesserung (+0.15)

### Sheet "Clusters" - Detaillierte Themen-Gruppen

| Cluster | Avg_Sentiment | Anzahl_Artikel |
|---------|---------------|----------------|
| Training_workshop | +0.88 | 8 |
| HR_recruiting | +0.75 | 12 |
| IT_software | +0.35 | 15 |
| Management_restructuring | -0.22 | 5 |

**Interpretation:**
- Workshop-AnkÃ¼ndigungen funktionieren hervorragend
- Recruiting-News kommen gut an
- Software-Updates kÃ¶nnten verstÃ¤ndlicher sein
- Restructuring-News erzeugen negative Reaktionen

### Sheet "Artikel" - Alle Artikel im Detail

VollstÃ¤ndige Liste mit:
- URL
- Titel
- Kategorie
- Cluster
- Durchschnittliches Sentiment
- Anzahl Kommentare (positiv/negativ/neutral)

### Sheet "Insights" - Top & Worst Artikel

- **Top 5 Artikel** mit bestem Feedback
- **Worst 5 Artikel** mit schlechtestem Feedback

## ğŸ¯ Actionable Insights

Basierend auf den Ergebnissen kannst du:

1. **Mehr von gut funktionierenden Artikel-Typen** verÃ¶ffentlichen
2. **Schlecht bewertete Artikel-Typen** verbessern oder vermeiden
3. **Spezifische Themen identifizieren** die gut/schlecht ankommen
4. **Content-Strategie anpassen**

## âš™ï¸ Eigene Kategorien hinzufÃ¼gen

Bearbeite `config/settings.py`:

```python
CATEGORY_KEYWORDS = {
    'HR': ['mitarbeiter', 'personal', 'recruiting', ...],
    'IT': ['software', 'hardware', 'system', ...],

    # FÃ¼ge eigene Kategorie hinzu:
    'Sustainability': ['nachhaltigkeit', 'umwelt', 'green', 'co2'],
    'Innovation': ['innovation', 'digital', 'transformation', 'ai'],
}
```

## ğŸ”§ Performance-Tipps

### Erste Verwendung (~60s Model Loading):
```
[3/6] Sentiment-Analyse der Kommentare...
Lade LLM Model (kann ~60s dauern)...
âœ“ LLM Model geladen (Mode: bert)
```
â†’ **Normal!** Das Model wird nur einmal geladen.

### Viele Artikel (>100):
```bash
# Verwende Lexikon-Modus (10x schneller)
python main_with_llm.py --input datei.xlsx --no-llm
```

### URLs nicht erreichbar:
```bash
# Ãœberspringe Web Scraping (nur Kommentar-Analyse)
python main_with_llm.py --input datei.xlsx --no-scraping
```

## ğŸ“ VollstÃ¤ndige Dokumentation

- **USAGE_GUIDE.md** - AusfÃ¼hrliche Anleitung mit allen Optionen
- **LLM Solution/CORPORATE_DEPLOYMENT.md** - Setup-Guide fÃ¼r Corporate-Umgebung
- **LLM Solution/README.md** - Technische Details zum LLM Model

## ğŸ†˜ Troubleshooting

### "Keine Input-Datei gefunden"
â†’ Lege Excel-Datei in `data/input/` ab

### "LLM Solution nicht verfÃ¼gbar"
â†’ Stelle sicher dass `LLM Solution/` Ordner existiert und Dependencies installiert sind

### "transformers nicht verfÃ¼gbar"
â†’ Installiere Dependencies:
```cmd
cd "P:\IMPORTANT\Projects\SentimentAnalysis\LLM Solution"
python -m pip install --no-index --find-links=wheels transformers torch
```

### "Scraping schlÃ¤gt fehl"
â†’ Verwende `--no-scraping` falls URLs nicht erreichbar sind

## âœ… Zusammenfassung

**Input:**
```
Excel mit URLs + Kommentaren
```

**Befehl:**
```bash
python main_with_llm.py --input data/input/meine_artikel.xlsx
```

**Output:**
```
Excel Report mit Antwort auf:
"Welche Artikel-Typen haben positives/negatives Feedback?"
```

**Ergebnis:**
```
Sheet "Kategorien" â†’ Sortiert nach Avg_Sentiment
â†’ Top-Kategorien = Beste Artikel-Typen!
```

---

**Los geht's! ğŸš€**

Lege deine Excel-Datei in `data/input/` und starte die Analyse!
